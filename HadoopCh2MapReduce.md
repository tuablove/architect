#HadoopCh2MapReduce

# 하둡 2장 - 맵리듀스 #


## 개념 ##
  1. 분산 처리
  1. 확장성(scalability)

### 단어 개수 세기(word counting) ###
  1. 문서에 포함된 각 단어의 출연 회수
  1. 맵리듀스 설명의 대표주자. (식상해)
  1. 입력 데이터
    1. 노드1 - He is a boy. He is.
    1. 노드2 - She is a girl. She is.
    1. 실제로는 아주 큰 데이터에 매우 많은 노드
  1. 노드1 매핑
    1. (he,1) (is,1) (a,1) (boy,1) (he,1) (is,1)
    1. (이 단어가, 1번 등장) 이란 뜻이다.
  1. 노드2 매핑
    1. (she,1) (is,1) (a,1) (girl,1) (she,1) (is,1)
  1. 노드별 컴바인(combine)이 가능한가?
    1. 워드 카운팅의 경우 컴바인이 가능하지만, 지금은 더 이상의 자세한 설명은 생략한다.
  1. 병합
    1. 같은 키를 가진 값들을 모은다.
    1. ` (he, [1,1]) `
    1. ` (is, [1,1,1,1]) `
    1. ` (a, [1,1]) `
    1. ` (boy, [1]) `
    1. ` (she, [1,1]) `
    1. ` (girl, [1]) `
    1. 하둡이 알아서 해 줌
  1. 리듀스
    1. 병합한 결과에 적합한 알고리즘을 적용하여 줄인다(reduce).
    1. 워드 카운팅에서 쓰는 알고리즘은 단순한 더하기!
    1. ` (he, [1,1]) -> (he,2) `
    1. ` (is, [1,1,1,1]) -> (is,4) `
    1. ` (a, [1,1]) -> (a,2) `
    1. ` (boy, [1]) -> (boy,1) `
    1. ` (she, [1,1]) -> (she,2) `
    1. ` (girl, [1]) -> (girl,1) `
    1. 단어 개수 세기 완료

### 컴바이너(Combiner) ###
  1. 컴바인이 가능한 작업, 불가능한 작업이 있다.
  1. 컴바인을 적용하면 전체 작업 속도가 매우 향상 됨
  1. 컴바인이란 - 각 노드에서 미리 알고리즘 적용 적용
  1. 위 예제에서 단어 is에 컴바인 적용 해 보자.
  1. 노드1
    1. (is,1) (is,1) -> (is, [1,1]) -> (is,2)
    1. 병합과 리듀스 과정 거침
    1. 컴바인과 리듀스 알고리즘은 동일 (다른 경우가 있을까?)
  1. 노드2
    1. (is,1) (is,1) -> (is, [1,1]) -> (is,2)
  1. 병합과 리듀스
    1. (is, [2,2]) -> (is,4)
    1. (is, [1,1,1,1]) -> (is,4) 컴바이너 없을 경우

### 연도별 최대온도 ###
  1. 노드1 입력 데이터
    1. 006701199099999 **1950** 051507004...9999999N9 **+0000** 1+99999999999...
    1. 004301199099999 **1950** 051512004...9999999N9 **+0022** 1+99999999999...
    1. 004301199099999 **1950** 051518004...9999999N9 **-0011** 1+99999999999...
    1. 004301265099999 **1949** 032412004...0500001N9 **+0111** 1+99999999999...
    1. 004301265099999 **1949** 032418004...0500001N9 **+0078** 1+99999999999...
    1. 연도와 화씨 온도는 원래 데이터에 없는 공백을 추가해 강조
  1. 노드2 입력 데이터
    1. 006701199099999 **1950** 051507004...9999999N9 **+0011** 1+99999999999...
    1. 004301199099999 **1950** 051512004...9999999N9 **+0019** 1+99999999999...
    1. 004301265099999 **1949** 032412004...0500001N9 **+0077** 1+99999999999...
    1. 004301265099999 **1949** 032418004...0500001N9 **+0088** 1+99999999999...
  1. 노드1 매핑
    1. (1950,0) (1950,22) (1950,-11) (1949,111) (1949,78)
    1. (연도, 측정온도)
  1. 노드2 매핑
    1. (1950,11) (1950,19) (1949,77) (1949,88)
  1. 컴바인이 가능 하다는게 사실입니까?
    1. 네, 사실입니다.
    1. 리듀스 알고리즘은 단순한 최대값 구하기!
    1. 노드1
      1. (1950, [0,22,-11]) -> (1950,22)
      1. (1949, [111,78]) -> (1949,111)
    1. 노드2
      1. (1950, [11,19]) -> (1950,19)
      1. (1949, [77,88]) -> (1949,88)
  1. 병합과 리듀스
    1. (1950, [22,19]) -> (1950,22)
    1. (1949, [111,88]) -> (1949,111)

### 기타 ###
  1. 다른 맵리듀스 예제 있으면 소개 부탁드려요.

### 구글은 지금... ###
  1. 구글의 외계인 고문은 계속 됩니다.
  1. Percolator - 2010년 구글은 웹 문서 인덱스를 맵리듀스에서 Percolator로 교체, 속도 100배!
  1. Pregel - 그래프 알고리즘 처리. 사람 사이의 관계 데이터 등. (Apache HAMA, 하마는 당신이 생각하는 그 하마)
  1. Dremel - 빠른 속도로 대규모 데이터를 해석하는 분산처리가 지원되는 도구(?)


## 구현 ##

### 하둡 생태계 ###
  1. hadoop echo system 으로 구글 이미지 검색
    1. 코끼리에다 돼지, 임팔라, 벌집, 동물원 관리자(...)까지 많기도 하다
  1. 요즘엔 JAVA 코딩 안 하고 HIVE로 쿼리만 날린다 카더라.

### JAVA 구현 ###
  1. 매퍼(mapper), 리듀서(reducer)를 만들어 잡(job)으로 실행
  1. 매퍼
    1. 클래스 ` Mapper<LongWritable, Text, Text, IntWritable> ` 상속
    1. 메소드 ` public void map(LongWritable key, Text value, Context context) ` 구현
  1. 리듀서
    1. 클래스 - ` Reducer<Text, IntWritable, Text, IntWritable> ` 상속
    1. 메소드 - ` public void reduce(Text key, Iterable<IntWritable> values, Context context) ` 구현
  1. 컴바이너
    1. 리듀서 재사용
  1. 잡
    1. main에서 ` Job job = new Job(); `
    1. 매퍼, 리듀서 설정
      1. 매퍼 - ` job.setMapperClass(MaxTemperatureMapper.class); `
      1. 컴바이너 - ` job.setCombinerClass(MaxTemperatureReducer.class); ` 리듀서 재사용
      1. 리듀서 ` job.setReducerClass(MaxTemperatureReducer.class); `
    1. 실행 - ` System.exit(job.waitForCompletion(true) ? 0 : 1); `
    1. 책에서 전체 코드를 참고하자.
  1. 타입(type)
    1. String - Text
    1. Long - LongWritable
    1. Integer - IntWritable
    1. 더 이상의 자세한...
  1. 컨텍스트(Context)
    1. 결과를 파일에 쓴다.

### 연도별 최대온도 구현 ###
  1. map
    1. ` public void map(LongWritable key, Text value, Context context) `
    1. 입력 파라미터
      1. (key, value) - (라인 넘버, 데이터)
      1. (0, 006701199099999 **1950** 051507004...9999999N9 **+0000** 1+99999999999...)
    1. 구현
      1. 단순한 substring
      1. 연도 - ` String year = line.substring(15, 19); `
      1. 온도
        1. 영상 - ` airTemperature = Integer.parseInt(line.substring(88, 92)); `
        1. 영하 - ` airTemperature = Integer.parseInt(line.substring(87, 92)); `
      1. Context 사용하여 결과를 파일로 저장
        1. ` context.write(new Text(year), new IntWritable(airTemperature)); `
  1. reduce
    1. ` public void reduce(Text key, Iterable<IntWritable> values, Context context) `
    1. 입력 파라미터
      1. (key, values) - (연도, 병합된 온도 값 배열)
      1. (1950, [19,22])
    1. 알고리즘은 단순한 최대값!
      1. ` maxValue = Math.max(maxValue, value.get()); `
    1. Context 사용하여 결과를 파일로 저장
      1. ` context.write(key, new IntWritable(maxValue)); `

### NEW vs OLD MapReduce API ###
  1. 결과 파일 이름에서 맵, 리듀스 구분
    1. part-nnnnn
    1. part-m-nnnnn, part-r-nnnnn
  1. 인터럽트에 반응
  1. 구현(implement)이 아니라 상속(extend)
  1. 매퍼, 리듀서에서 run() 오버라이딩 가능
  1. 잡 설정 Configuration
  1. OLD API 코드는 생략

### 데이터 흐름 ###
  1. 셔플!
    1. 더 이상의 ...

### 하둡 스트리밍 ###
  1. 표준 입력, 표준 출력을 입출력으로 사용.
  1. 그러므로 다양한 언어 사용 가능
  1. MapReduce API 제한 없음
  1. 유용할까?

### 하둡 파이프 ###
  1. C++ 인터페이스
  1. 표준 입출력 대신 소켓 사용
  1. 더 이상...
  1. C++ 주력이신 분들은 이번 기회에 자바에 익숙해져 보아요.

### 최대 온도 복습 ###
  1. 반복

(끝)